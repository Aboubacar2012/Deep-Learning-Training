{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project: CNN-Handwritten Digit Recognition-Simple Convolutional Neural Network for MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/ZerKLbzLAxv4P9DuOjGi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aboubacar2012/Deep-Learning-Training/blob/main/Project_CNN_Handwritten_Digit_Recognition_Simple_Convolutional_Neural_Network_for_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Convolutional Neural Network for MNIST"
      ],
      "metadata": {
        "id": "hV0Zg1DIBvey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have seen how to load the MNIST dataset and train a simple Multilayer Perceptron\n",
        "model on it, it is time to develop a more sophisticated convolutional neural network or CNN\n",
        "model. Keras does provide a lot of capability for creating convolutional neural networks. In this\n",
        "section we will create a simple CNN for MNIST that demonstrates how to use all of the aspects\n",
        "of a modern CNN implementation, including Convolutional layers, Pooling layers and Dropout\n",
        "layers. The first step is to import the classes and functions needed."
      ],
      "metadata": {
        "id": "lPxrTI2FC3b5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m_Vw-ddhBnWc"
      },
      "outputs": [],
      "source": [
        "# Import classes and functions\n",
        "import numpy \n",
        "from keras.datasets import mnist \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "from keras.layers import Dropout \n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_first')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fix random for reproducibility\n",
        "seed=7\n",
        "numpy.random.seed(seed)"
      ],
      "metadata": {
        "id": "c1ptnQXQDof5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we need to load the MNIST dataset and reshape it so that it is suitable for use training\n",
        "a CNN. In Keras, the layers used for two-dimensional convolutions expect pixel values with the\n",
        "dimensions [channels][width][height]. In the case of RGB, the first dimension channels\n",
        "would be 3 for the red, green and blue components and it would be like having 3 image inputs\n",
        "for every color image. In the case of MNIST where the channels values are gray scale, the pixel\n",
        "dimension is set to 1."
      ],
      "metadata": {
        "id": "AUQbMPycEOzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data \n",
        "(X_train, y_train),(X_test, y_test)=mnist.load_data()\n",
        "# Reshape to be [sample][channels][width][height]\n",
        "X_train=X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
        "X_test=X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbPwrYSADucc",
        "outputId": "1133f7bb-60d7-474b-eef0-61249f81ef5f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize input from 0-255 to 0-1\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "#One hot encode outputs \n",
        "y_train=np_utils.to_categorical(y_train)\n",
        "y_test=np_utils.to_categorical(y_test)\n",
        "num_classes=y_test.shape[1]"
      ],
      "metadata": {
        "id": "T6m7A6LTE5Ek"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we define our neural network model. Convolution neural networks are more complex than standard Mutilayer Perceptron, so will start by using a simple structure to begin with that uses all of the elements for state-of-the-art results. Below summarizes the network architecture."
      ],
      "metadata": {
        "id": "YXs_YcusFn0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The first hidden layer is a convolutional layer called a Convolution2D. The layer has 32 feature maps, which with the size of 5x5 and a rectifier activation function. This is the input layer, expecting images with the structure outline above \n",
        "\n",
        "- Next we define a pooling layer that takes the maximun value called MaxPooling2D. It is configured with a pool size of 2x2.\n",
        "\n",
        "- The next layer is a regularization layer using dropout called Dropout. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n",
        "\n",
        "- Next is a layer that converts the 2D matrix data to a vector called Flatten. It allows the output to be processed by standard fully connected layers.\n",
        "\n",
        "- Next a fully connected layer with 128 neurons and rectifier activation function is used.\n",
        "\n",
        "- Finally, the ouput layer has 10 neurons for the 10 classes and a softmax activation function to output probability-like prediction for each class.\n",
        "\n",
        "As before, the model is trained using logarithm loss and the ADAM gradient descent algorithm."
      ],
      "metadata": {
        "id": "A9n0C3rtGBhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and Compile CNN Model\n",
        "def baseline_model():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Convolution2D(32, 5, 5, input_shape=(1, 28, 28), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  # Compile model\n",
        "  model.compile(loss='categorical_crossentropy' , optimizer='adam' , metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "2teklkM_Fcai"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit and Evaluate The CNN Model\n",
        "model=baseline_model()\n",
        "# Fit the model \n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model \n",
        "scores=model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srNAcvieJlYU",
        "outputId": "ac8f83f8-ae9f-47a4-e1ef-555a200d615b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 14s - loss: 1.1663 - accuracy: 0.6277 - val_loss: 0.5820 - val_accuracy: 0.8306 - 14s/epoch - 48ms/step\n",
            "Epoch 2/10\n",
            "300/300 - 1s - loss: 0.6321 - accuracy: 0.8008 - val_loss: 0.4444 - val_accuracy: 0.8659 - 1s/epoch - 4ms/step\n",
            "Epoch 3/10\n",
            "300/300 - 1s - loss: 0.5298 - accuracy: 0.8320 - val_loss: 0.3731 - val_accuracy: 0.8893 - 1s/epoch - 4ms/step\n",
            "Epoch 4/10\n",
            "300/300 - 1s - loss: 0.4737 - accuracy: 0.8499 - val_loss: 0.3418 - val_accuracy: 0.8972 - 1s/epoch - 4ms/step\n",
            "Epoch 5/10\n",
            "300/300 - 1s - loss: 0.4397 - accuracy: 0.8618 - val_loss: 0.3084 - val_accuracy: 0.9081 - 1s/epoch - 4ms/step\n",
            "Epoch 6/10\n",
            "300/300 - 1s - loss: 0.4108 - accuracy: 0.8699 - val_loss: 0.2888 - val_accuracy: 0.9110 - 1s/epoch - 4ms/step\n",
            "Epoch 7/10\n",
            "300/300 - 1s - loss: 0.3889 - accuracy: 0.8764 - val_loss: 0.2745 - val_accuracy: 0.9173 - 1s/epoch - 4ms/step\n",
            "Epoch 8/10\n",
            "300/300 - 1s - loss: 0.3686 - accuracy: 0.8827 - val_loss: 0.2613 - val_accuracy: 0.9195 - 1s/epoch - 4ms/step\n",
            "Epoch 9/10\n",
            "300/300 - 1s - loss: 0.3576 - accuracy: 0.8865 - val_loss: 0.2540 - val_accuracy: 0.9211 - 1s/epoch - 4ms/step\n",
            "Epoch 10/10\n",
            "300/300 - 1s - loss: 0.3452 - accuracy: 0.8889 - val_loss: 0.2481 - val_accuracy: 0.9240 - 1s/epoch - 4ms/step\n",
            "CNN Error: 7.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XNelRD2HKMOa"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}